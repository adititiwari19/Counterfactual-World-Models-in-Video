# URSA Fall 2025: Counterfactual World Models in Video  

Mentor: **Aditi Tiwari (CS @ UIUC)**  
Mentees: **Tia Shrikhande & Abhay Pokhriyal**  

---

## ğŸ“Œ Project Overview  
This project explores **counterfactual world models in video** â€” AI systems that do not just predict *what happens next*, but also *what could have happened if something were different*.  

Example:  
- Video shows someone picking up a hammer.  
- Counterfactual question: *â€œWhat if they didnâ€™t pick it up?â€*  

Through toy experiments, we aim to build a **prototype system** that links narration, visual frames, and counterfactual reasoning.  

---

## ğŸ¯ Goals  
- Learn research skills through hands-on experimentation.  
- Build a **prototype system** and a **final write-up/demo**.  
- Potentially submit to a **workshop-style paper** (stretch goal).  
- Emphasize learning, curiosity, and collaboration.  

---

## ğŸ›  Tools & Libraries  
We will primarily use **Google Colab** (free GPU runtime) for development.  

Core libraries and models:  
- [OpenCV](https://opencv.org/) â†’ frame extraction, video handling  
- [PyTorch](https://pytorch.org/) â†’ ML backbone  
- [CLIP](https://github.com/openai/CLIP) â†’ image-text alignment  
- [Whisper](https://github.com/openai/whisper) â†’ speech-to-text transcription  
- [VideoMAE / TimeSformer](https://github.com/MCG-NJU/VideoMAE) â†’ video embeddings (later stages)  

---

---

## ğŸš€ Starter Experiment (Weeks 2â€“3)  
Goal: Given a short video (5â€“10s), link narration words to the correct video frame.  

**Steps:**  
1. Pick a toy video (e.g., someone lifting a cup/hammer).  
2. Run **Whisper** â†’ extract transcript.  
3. Use **OpenCV** â†’ extract 1 frame per second.  
4. Use **CLIP** â†’ encode frames + encode a keyword from transcript (e.g., *â€œhammerâ€*).  
5. Compare similarity scores across frames.  
6. Plot results: *frame index vs. similarity*.  

Expected outcome: A simple, visible demo where AI finds the right frame for the mentioned object.  

---

## âœ… Week 1 To-Do  
- [ âœ… ] Set up communication channel (Slack/Discord/Group chat).  - Weekly meeting on Thursday over Zoom at 5:30PM
- [ ] Clone this repo & make first commit.  
- [ ] Test a Colab notebook with basic imports (`opencv`, `torch`, `clip`, `whisper`).  
- [ ] Skim background on **World Models** and **Counterfactual Reasoning**.  
- [ ] Share 1â€“2 related papers or interesting links in our notes.  

---

## ğŸ“– References  
- Hafner et al. (Dreamer): [https://arxiv.org/abs/1912.01603](https://arxiv.org/abs/1912.01603)  
- OpenAI CLIP: [https://arxiv.org/abs/2103.00020](https://arxiv.org/abs/2103.00020)  
- OpenAI Whisper: [https://arxiv.org/abs/2212.04356](https://arxiv.org/abs/2212.04356)  

